import streamlit as st
import sys
import os
import pdfplumber
from openai import OpenAI
from datetime import datetime
from dotenv import load_dotenv

# ìƒìœ„ ë””ë ‰í† ë¦¬ì˜ utils ëª¨ë“ˆ importë¥¼ ìœ„í•œ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="AI_ë¦¬í¬íŠ¸ ìƒì„±ê¸°",
    page_icon="ğŸ“‹",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì»¤ìŠ¤í…€ CSS
st.markdown("""
<style>
    .info-container {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 25px;
        border-radius: 15px;
        color: white;
        margin: 20px 0;
        box-shadow: 0 4px 15px rgba(0,0,0,0.1);
    }
    .data-source-card {
        background: white;
        padding: 20px;
        border-radius: 10px;
        box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        margin: 15px 0;
        border-left: 5px solid #1f77b4;
    }
    .update-card {
        background: linear-gradient(135deg, #74b9ff 0%, #0984e3 100%);
        padding: 15px;
        border-radius: 10px;
        color: white;
        margin: 10px 0;
    }
    .system-info {
        background: linear-gradient(135deg, #00b894 0%, #00a085 100%);
        padding: 20px;
        border-radius: 15px;
        color: white;
        margin: 15px 0;
    }
    .guide-section {
        background: #f8f9fa;
        padding: 20px;
        border-radius: 10px;
        margin: 15px 0;
        border: 1px solid #e9ecef;
    }
</style>
""", unsafe_allow_html=True)

# íƒ€ì´í‹€
st.markdown('<h1 class="main-header">ğŸ“„ AI ê¸°ë°˜ ë³´ê³ ì„œ ìƒì„±ê¸°</h1>', unsafe_allow_html=True)

# OpenAI API Key ë¡œë”©
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
os.environ["OPENAI_API_KEY"] = os.getenv("OPENAI_API_KEY")



# PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
@st.cache_data
def extract_text_from_pdf(uploaded_file):
    with pdfplumber.open(uploaded_file) as pdf:
        text = ""
        for page in pdf.pages:
            page_text = page.extract_text()
            if page_text:
                text += page_text + "\n"
    return text

# ëª©ì°¨ ì¶”ì¶œ í•¨ìˆ˜
def extract_table_of_contents(text):
    prompt = f"""
ë‹¤ìŒ ë¬¸ì„œì—ì„œ **ëª©ì°¨(ì°¨ë¡€)**ì— í•´ë‹¹í•˜ëŠ” ë¶€ë¶„ë§Œ ì •í™•íˆ ì¶”ì¶œí•´ ì£¼ì„¸ìš”.
- ìˆ«ìë‚˜ ë¡œë§ˆì, ì œëª© íŒ¨í„´ì„ ì´ìš©í•´ ëª©ì°¨ í•­ëª©ë§Œ ë½‘ì•„ì£¼ì„¸ìš”.
- ë³¸ë¬¸ ë‚´ìš©ì€ í¬í•¨í•˜ì§€ ë§ê³ , ëª©ì°¨ êµ¬ì¡°ë§Œ ì¶œë ¥í•˜ì„¸ìš”.

ë¬¸ì„œ ë‚´ìš©:
{text[:4000]}
"""
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ë¬¸ì„œ êµ¬ì¡°ì—ì„œ ëª©ì°¨ë§Œ ì •í™•íˆ ì¶”ì¶œí•˜ëŠ” AIì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.3
    )
    return response.choices[0].message.content.strip()

# ë¬¸ì„œ ì „ì²´ êµ¬ì¡° ìš”ì•½
def summarize_template_structure(text):
    prompt = f"""
ë‹¤ìŒ ë¬¸ì„œì˜ í˜•ì‹(ë³´ê³ ì„œ êµ¬ì¡°, ì œëª© ìŠ¤íƒ€ì¼, êµ¬ì„± íë¦„ ë“±)ì„ ê°„ë‹¨íˆ ìš”ì•½í•´ ì£¼ì„¸ìš”.
- ë¬¸ì„œê°€ ì–´ë–¤ í˜•ì‹ìœ¼ë¡œ ì‘ì„±ë˜ì–´ ìˆëŠ”ì§€ ì„¤ëª…í•´ì£¼ì„¸ìš”.
- ëª©ì°¨, ë³¸ë¬¸ êµ¬ì„±, ì–¸ì–´ í†¤ ë“±ì„ í¬í•¨í•´ í˜•ì‹ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.

ë¬¸ì„œ ë‚´ìš©:
{text[:4000]}
"""
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ë¬¸ì„œ í˜•ì‹ì„ ë¶„ì„í•˜ê³  ìš”ì•½í•˜ëŠ” AIì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.5
    )
    return response.choices[0].message.content.strip()

# ì£¼ì œ ê¸°ë°˜ ë³´ê³ ì„œ ìƒì„±
def generate_report_based_on_template(topic, template_text):
    prompt = f"""
ì•„ë˜ ë¬¸ì„œ í˜•ì‹ì„ ì°¸ê³ í•˜ì—¬, ìƒˆë¡œìš´ ì£¼ì œ '{topic}'ì— ëŒ€í•´ ë™ì¼í•œ í˜•ì‹ì˜ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”.

- ë¬¸ì„œ í˜•ì‹(ëª©ì°¨, êµ¬ì„±, ë§íˆ¬ ë“±)ì€ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ë˜,
- ë‚´ìš©ì€ '{topic}'ì„ ê¸°ë°˜ìœ¼ë¡œ ì™„ì „íˆ ìƒˆë¡­ê²Œ ì‘ì„±í•´ ì£¼ì„¸ìš”.

ğŸ“„ ì°¸ê³  ë¬¸ì„œ:
{template_text[:4000]}
"""
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ë³´ê³ ì„œ í˜•ì‹ì„ í•™ìŠµí•´ ìƒˆë¡œìš´ ì£¼ì œì— ë§ì¶° ì‘ì„±í•˜ëŠ” AIì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.7
    )
    return response.choices[0].message.content.strip()

# ì‚¬ìš©ì ì…ë ¥ UI
uploaded_file = st.file_uploader("ğŸ“ PDF ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["pdf"])

# Step 1: ë¬¸ì„œ ì—…ë¡œë“œ ì‹œ ë‚´ìš© ìš”ì•½ ë° ëª©ì°¨ ì¶”ì¶œ
if uploaded_file:
    with st.spinner("ë¬¸ì„œ ë¶„ì„ ì¤‘..."):
        extracted_text = extract_text_from_pdf(uploaded_file)

        toc = extract_table_of_contents(extracted_text)
        structure_summary = summarize_template_structure(extracted_text)

    st.subheader("ğŸ§¾ ë¬¸ì„œ ëª©ì°¨ ìë™ ì¶”ì¶œ")
    st.code(toc, language="markdown")

    st.subheader("ğŸ“š ë¬¸ì„œ í˜•ì‹ ìš”ì•½")
    st.markdown(structure_summary)

topic = st.text_input("ğŸ“ ìƒˆë¡œ ì‘ì„±í•  ë³´ê³ ì„œ ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: íƒ„ì†Œì¤‘ë¦½ ì¶”ì§„ ì „ëµ")

# Step 2: ì£¼ì œ ì…ë ¥ í›„ ë³´ê³ ì„œ ìƒì„±
if uploaded_file and topic:
    with st.spinner("ğŸ“„ ìƒˆë¡œìš´ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
        generated_report = generate_report_based_on_template(topic, extracted_text)
    st.success("âœ… ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ!")

    st.download_button(
        "ğŸ“¥ ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ",
        generated_report,
        file_name=f"{topic}_ë³´ê³ ì„œ.txt",
        mime="text/plain"
    )

    st.text_area("ğŸ“„ ìƒì„±ëœ ë³´ê³ ì„œ ë¯¸ë¦¬ë³´ê¸°", generated_report, height=500)